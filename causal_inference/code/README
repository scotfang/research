STATUS: this document is out of date.

* results directory contains several different levels of results, including transient results/logs, but also things that feed into generating other results....
* testingCutPoints.txt is used or generated by dealWithDBResults.py and extractingActionResults.m
* analyzeData.py, analyze_results.R, and analyze_results.go go together; analyze_results.R and analyze_results.go primarily by Mingtian, originally named amy.R and amy.go if referenced elsewhere
* the CVPR2012_* directories consist of action detections; 
** some are directories of directories of frames per event (these are the source data from Ping, if they're pure action detections; from Mingtian if they're parsed). txt files per frame per event along with .mat files
** the following matlab files were to smooth the skeleton data: extractingActionResults.m  slidingWindow.m getCutPoints.m             writeTemporalParses.m
** the various directories (smoothed, smoothed monday, smoothed monday 1000, slidingwindow, etc) are the results of trying different approaches to smoothing the skeleton data to make detections more accurate
** CVPR2012_fluent_result are fluent detection results from Bruce
** results/cvpr_db_results* are exports of "human" fluent and action detections against the same videos
** results/Exp2_output_data.txt is used by demo.py


-----------------------------------------------------------------------
demo.py - for testing functionality, and in some cases actually running experiments
-----------------------------------------------------------------------

from temporal parsing, we get:
	* fluent_parses -- dict 
		key = frame number (only for those that had a change)
		value = dict 
			key = fluent symbols that changed value 
			value = corresponding energy
	* temporal_parses -- dict
		key = frame number
		value = dict
			key = event symbols that completed
			value = dict
				key = energy -> value = energy
				key = agent -> value = agent UUID

*defines the causal_forest (the causal grammar) -- array of dicts
	one dict is one causal tree
		'node type' in {root, and, leaf, (or?)}
		'symbol type' in {fluent, event, prev_fluent}
		'symbol' which fluent/event (sometimes non-existent if unnamed node)
		'probability' or-probability
		'timeout' time out on action (how long we're willing to wait for the fluent change to happen)
		'children' an array of dicts.  NOTE: children is a new causal forest!  

* might call causal_grammar.import_csv to bring in the old data from last year

* calls causal_grammar.process_events_and_fluents() to parse things

-----------------------------------------------------------------------
-----------------------------------------------------------------------
causal_grammar.py
-----------------------------------------------------------------------

---
(L254) def process_events_and_fluents() == MAIN FUNCTION
	Inputs: causal_forest, fluent_parses, temporal_parses, (all defined above)
		fluent_thresh_on_energy (at what point do we call the fluent "on" -- we used 0.7 (or higher)), 
		fluent_thresh_off_energy (at what point call "off" -- we used 0.3 (or lower)),
		reporting threshold (ideally, only return parses above this point)

	fluent_parse_index, temporal_parse_index both initialized to 0 (for tracking which ST-parse we're on)
	fluent_parses.get returns the keys of fluent_parses (here the frames)
	sorted(fluent_parses, key=fluent_parses.get) returns an array, sorted by frame #
	so then isn't fluent_parse_frames.sort() redundant?  sort of, yes.  but that wasn't working because you can't sort a dict...

	(L267) get_fluent_and_event_keys_we_care_about(causal_forest) returns a dict of lists of the symbols (ie: one list for "fluents", one list for "events")
	
	initialize event_hash = {}, fluent_hash = {} (for attaching fluent/event keys to each causal tree)

	(L271) get_event_timeouts(causal_forest) returns a dict where symbol -> timeout

	CREATE EVENT_HASH, FLUENT_HASH
	(L272) for each causal_tree in the forest <-  compile the event and fluent hashes for the lookups
		get the keys (different than before because is only for one tree in the forest).  so keys["events"] = list of event symbols, keys["fluents"] = list for fluents
		construct event_hash
			for each event key (event symbol), event_hash[key] is a dict with: agent = False, frame = -1, energy = unknown, trees = [causal_tree, causal_tree, causal_tree, ...].  Initialized this way because as we run, we will update agent, frame, energy with values from the temporal parse.  This indicates that each event has only one of each.
			for each fluent key (fluent_symbol), fluent_hash[key] is a dict with: energy = unknown, prev_energy = unknown, trees = [causal_tree, causal_tree, ...], status = kFluentStatusUnknown

	PRODUCE PARSE HASHES
	(L287) initialize parse_id = 0, parse_array = [], parse_id_hash_by_fluent = {}, parse_id_hash_by_event = {}
	for each causal_tree in causal_forest, find all parses: causal_tree["parses"] = generate_parses(causal_tree) <- returns a forest where each option is a different parse.  the parses have the same format as trees (but or-nodes now only have one option selected). put all the parses in parse_array, a dict with "id" and parse.
	for each parse, make lookups by event (parse_id_hash_by_event) and by fluent (parse_id_hash_by_fluent), where each contains a list of parse_id's corresponding to each symbol.

	LOOP THROUGH PARSES, GETTING FRAMES CHANGE IN.  FLUENT GETS HANDLED FIRST.
	(L316) initialize active_parse_trees = {} as dict (later: id -> parse{parse stuff, frame (frame last updated), })
	while fluent_parse_index (initialized to 0, incremented within) is less than the length of the fluent_parses we have (likewise with temporal parses), then there's still ST-parse information to work through, so...
		check if we've done all the fluents/temporal parses
		HANDLE FLUENTS FIRST
		if fluents not done and it's before the next temporal temporal parse
			assign current fluent frame to frame
			complete_outdated_parses - forces completion on any parse that has timed out.  additionally, also forces completion on any parses that have the same primary symbol as the parse that timed out.  modifies active_parse_trees by dropping those that were completed.
			clear_outdated_events <- for events that have timed out, reset event_hash for those events with frame = -1, energy = kUnknownEnergy, agent = False.

			(L324) get the changes we care about with filter_changes
			initialize fluents_actually_change = []
			for fluent in changes
				initialize fluent_changed = False
				get the fluent_on_energy, convert to probability.  calculate the fluent_off_probability.  convert to fluent_off_energy.  write FLUENT_on and FLUENT_off as strings for each fluent value.  
				get current "status" on each fluent_off and fluent_on from fluent_hash.  "status" is just 1 2 or 3 for on/off.

				(L344) check if these fluents changed (went to true) to consider starting a parse:
				if fluent_on_status (ie: previous status) is Unknown or Off, and if fluent_on_energy (ie: current status) is below fluent_threshold_on_energy (which is fed into the function), then energy is low enough to be considered "on" now.
					THEN fluent_changed = fluent_on_string, and set status in fluent_hash to ON.
				else if fluent_on_energy too high (higher than off threshold), set status in fluent hash to OFF.

				vice versa.  if fluent_off was UNKNOWN/OFF, and if energy is now low enough to be considered ON, mark fluent_changed as fluent_off_string, and change fluent_hash status for fluent_off_string to ON. // this is for a change _to_ off.
				else if fluent_off_energy is high enough to be OFF, set status to OFF

				(L354) set energies in fluent_hash for "prev_energy" and "energy" for both ON/OFF strings.

				(L361) if fluent_changed, append the fluent symbol to the list fluents_actually_changed
					for each parse_id that has the changed fluent symbol, add id/parse to active_parse trees (key = parse_id, value = parse_array[parse_id])

			(L369) complete any of active_parse_trees that had a primary fluent change (with or without the action), and remove those trees from the active_parse_trees dict
			kFilterNonEventTriggeredParseTimeouts -- we added a bunch of parses to active_parse_trees.  if a non-primary fluent changed, but we didn't see a causing event, this allows us to expel them from consideration
	??? doesn't this expel any active_parse_trees that do not have main symbol of the first fluent *** BUG!!!

		(L379) ELSE (moving on to temporal parses, so the fluents for the time has been completed)
			frame is now current from temporal_parse_frames
			complete_outdated_parses <- forces completion on any parse that has timed out.  additionally, also forces completion on any parses that have the same primary symbol as the parse that timed out.  modifies active_parse_trees by dropping those that were completed.
			filter_changes from the temporal_parses (really just means get the temporal information for the keys we care about)
			for each event that changed, set it's energy, agent, and frame in event_hash.  Then make sure all parses containing that event symbol are in our active parse list.
---

--------
NOTE: when a parse is created
* if new information suggests to (ie: if temporal_parse has symbol that is in a parse that's not yet in active parses, same for fluent_parses)
* if kFilterNonEvent..., only parses are added in the fluent scape where fluent changed is a main fluent.

NOTE: when a parse is completed
* after getting new temporal, fluent parse information, complete_outdated_parses
	-- if completing a timed out parse (ie: current frame is now further away from last update than the max_event_timeout for the tree), try to complete all parse trees with the same main symbol.
* if main fluent symbol changes, complete_parse_tree

SO: if event detection occurs _after_ fluent change (due to detection errors), we will miss it 
-------
 
---
(L80) def get_fluent_and_event_keys_we_care_about(causal_forest)
	recursively navigate through the forest
	collect all "event" symbol types
	collect all "fluent" symbol types
---

---
(L64) def get_event_timeouts(forest)
	recursively get all event timeouts
	if tree has "event" symbol_type
		events[EVENT_NAME] = (the given timeout or kDefaultTimeout (assigned at top of causal_grammar.py))
---

---
(L112) def generate_parses(causal_tree)
	get the node_type from the causal tree.
	initialize partial_causal_parses = []
	if no children, return the causal tree
	if children, current_node is a copy of the node without the children.  
		if the current_node is an or-node, generate parses for each child.  make each parse into a tuple as children for current_node (current_node["children"] = (parse,)), then add current_node to partial_causal_parses.
		if the current node is an and-node, then for each child of the node, generate parses and put these parses in a child_parses list.  so child_parses is a list of lists where each item in child_parses is a list of all parses corresponding to that child node.  then we take the cartesian product of all possibilities (all options possible for mixing those child parses on the and-node.  
			// NOTE: product() is equivalent to nested for-loops in a generator expression. For example, product(A, B) returns the same as ((x,y) for x in A for y in B)
			* means every item in the list is an argument
			** means every item in a dict is a named argument

	NOTE: sometimes generate_parses returns a tuple, sometimes a list.  
---

---
(L220) def complete_outdated_parses(active_parse_trees, parse_array, fluent_hash, event_hash, event_timeouts, frame, reporting_threshold_energy)
	LOOP THROUGH THE ACTIVE PARSES
	for each parse_id in active_parses_copy
		active_parse = parse_array[parse_id] <- contains a tree for the parse
		find the max_event_timeout over all events in the parse (this is the max number of frames we're willing to wait for the parse to complete)
		if parse has timed out (parse was last updated longer ago than max_event_timeout), 
			remove from active_parses (Note: changing active_parse_trees here)
			set "completed time" to the last time on the parse + max_event_timeout
			complete_parse_tree (so calculate the energy, find the agents, print it out)
			then complete others where this fluent was primary.  this is because if the event like "touch light switch" was recorded, but the light didn't actually change, the inertial is a better explanation.  completing others that have the same primary fluent allows us to see if there's a better explanation (ie: is the action ignorable)
---

---
(L200) def complete_parse_tree(active_parse, fluent_hash, event_hash, effective_frame)
	calculate the energy of the parse
	find the agents involved through the event_hash -- there is only one agent allowed per action, but there might be multiple actions.
	print it out
---

---
(L139) def calculate_energy(active_parse_tree, fluent_hash, event_hash)
	add up over the nodes recursively (turning probabilities into energy by -log(prob))
	note: if tmp_energy != (L144)... is a hold over from old way.  and wasn't working then.  
	note: unknown energies were first initialized when creating event_hash and fluent_hash.
---

---
(L191) def clear_outdated_events(event_hash, event_timeouts, frame)
	for any events that have timed out, reset event_hash for those events with frame = -1, energy = kUnknownEnergy, "agent" = False.
---

---
(L97) def filter_changes(changes, keys_in_grammar)
	remove from the changes anything we don't actually care about
---

---
print_previous_energies

print_current_energies

make_tree_like_lisp

hr

import_csv

---

